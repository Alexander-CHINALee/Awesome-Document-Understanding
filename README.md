# Awesome-Document-Understanding [![Awesome](https://awesome.re/badge-flat.svg)](https://awesome.re)
> A repository used to collect various document artifical intelligence

Paper format: [year pub] [paper title] [[Paper link]]()[[Code link]]()

continue update ðŸ¤—

## Table of contents

- [Document Understanding](#document-understanding)

# Document Understanding

**2023**

`2023 ICLR` StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training **(Baidu)** [[Paper]](https://arxiv.org/abs/2303.00289)[[Code]](https://github.com/PaddlePaddle/VIMER/tree/main/StrucTexT)

`2023 ACL` Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding **(Huawei)** [[Paper]](https://arxiv.org/abs/2212.09621)[Code]

`2023 CVPR` Unifying Vision, Text, and Layout for Universal Document Processing **(Microsoft)** [[Paper]](https://arxiv.org/abs/2212.02623)[[Code]](https://github.com/microsoft/i-Code/tree/main/i-Code-Doc)

**2022**

`2022 CVPR` XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich Document Understanding **(Alibaba)** [[Paper]](https://arxiv.org/abs/2203.06947)[[Code Unofficial]](https://github.com/Sanster/xy-cut)

`2022 ACM MM` LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking **(Microsoft)** [[Paper]](https://arxiv.org/abs/2204.08387)[[Code]](https://github.com/microsoft/unilm/tree/master/layoutlmv3)

`2022 ACM MM` DiT: Self-supervised Pre-training for Document Image Transformer **(Microsoft)** [[Paper]](https://arxiv.org/abs/2203.02378)[[Code]](https://github.com/microsoft/unilm/tree/master/dit)

`2022 arXiv` ERNIE-Layout: Layout Knowledge Enhanced Pre-training for Visually-rich Document Understanding **(Baidu)** [[Paper]](https://arxiv.org/abs/2210.06155)[[Code]](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-layout)

`2022 NIPS` Wukong: A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark **(Huawei)** [[Paper]](https://arxiv.org/abs/2202.06767)[[Code]](https://wukong-dataset.github.io/wukong-dataset/)




**2021**

`2021 NIPS` Unified Pretraining Framework for Document Understanding **(Adobe)** [[Paper]](https://arxiv.org/abs/2204.10939)[Code]

`2021 arXiv` LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding **(Microsoft)** [[Paper]]([https://arxiv.org/abs/2204.10939](https://arxiv.org/abs/2104.08836))[[Code]](https://github.com/microsoft/unilm/tree/master/layoutxlm)

`2021 EMNLP` LayoutReader: Pre-training of Text and Layout for Reading Order Detection **(Microsoft)** [[Paper]](https://arxiv.org/abs/2108.11591)[[Code]](https://github.com/microsoft/unilm/tree/master/layoutreader)

`2021 ICDAR` Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer **(Applica)** [[Paper]](https://arxiv.org/abs/2102.09550)[[Code]](https://github.com/uakarsh/TiLT-Implementation)



**2020**

`2020 arXiv` LayoutLMv2: Multi-modal Pre-training for Visually-rich Document Understanding **(Microsoft)** [[Paper]](https://arxiv.org/abs/2012.14740)[[Code]](https://github.com/microsoft/unilm/tree/master/layoutlmv2)

`2020 KDD` LayoutLM: Pre-training of Text and Layout for Document Image Understanding **(Microsoft)** [[Paper]](https://arxiv.org/abs/1912.13318)[[Code]](https://github.com/microsoft/unilm/tree/master/layoutlm)




